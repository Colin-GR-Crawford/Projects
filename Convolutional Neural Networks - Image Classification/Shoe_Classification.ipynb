{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shoe Classification Using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIM: The aim of the project is to biuld a model using Convolutional Neural Networks, which correctly classifies images of mens shoes according to their type. The model will be constructed using Keras with TensorFlow as the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, MaxPooling2D, Dropout\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine=create_engine('postgresql://localhost:5432/capstone_project')\n",
    "Data=pd.read_sql_table('mens_shoes_cleaned',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define the shoe 'type' key words in order\n",
    "Shoe_Types=[u'boots',u'loafers',u'derby',u'sneakers',u'brogues',u'ankle',u'oxfords',u'chelsea',\n",
    "            u'monk',u'trainers',u'hightops',u'slippers',u'driving',u'gommino',u'drivers',u'chukka',\n",
    "            u'sandals',u'slip',u'moccasin',u'lace']\n",
    "\n",
    "\n",
    "## Creating a function that searches through the shoe type list, and if the type is found returns the type.\n",
    "def shoe_type1(Inp_Str,Shoe_Types):\n",
    "    for x in Shoe_Types:\n",
    "        if x in Inp_Str:\n",
    "            return x\n",
    "## Creating a function that searches through the shoe type list, and if the type is found returns the type IF \n",
    "## the type has not already been assigned\n",
    "def shoe_type2(Inp_Str,Type1,Shoe_Types):\n",
    "    for x in Shoe_Types:\n",
    "        if x!=Type1:\n",
    "            if x in Inp_Str:\n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>retailer</th>\n",
       "      <th>description</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_url_alt</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>alexander mcqueen</td>\n",
       "      <td>Matches_Fashion</td>\n",
       "      <td>raised sole hightops leather trainers</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>trainers</td>\n",
       "      <td>hightops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729</td>\n",
       "      <td>armando cabral</td>\n",
       "      <td>Matches_Fashion</td>\n",
       "      <td>lace up leather derby shoes</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>405.0</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>derby</td>\n",
       "      <td>lace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>bottega veneta</td>\n",
       "      <td>Matches_Fashion</td>\n",
       "      <td>intrecciato leather loafers</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>loafers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731</td>\n",
       "      <td>armando cabral</td>\n",
       "      <td>Matches_Fashion</td>\n",
       "      <td>lizard effect leather ankle boots</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>boots</td>\n",
       "      <td>ankle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732</td>\n",
       "      <td>burberry</td>\n",
       "      <td>Matches_Fashion</td>\n",
       "      <td>owen tread sole canvas boots</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>http://assetsprx.matchesfashion.com/img/produc...</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>boots</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id              brand         retailer  \\\n",
       "0  728  alexander mcqueen  Matches_Fashion   \n",
       "1  729     armando cabral  Matches_Fashion   \n",
       "2  730     bottega veneta  Matches_Fashion   \n",
       "3  731     armando cabral  Matches_Fashion   \n",
       "4  732           burberry  Matches_Fashion   \n",
       "\n",
       "                             description  \\\n",
       "0  raised sole hightops leather trainers   \n",
       "1            lace up leather derby shoes   \n",
       "2            intrecciato leather loafers   \n",
       "3      lizard effect leather ankle boots   \n",
       "4           owen tread sole canvas boots   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  http://assetsprx.matchesfashion.com/img/produc...   \n",
       "1  http://assetsprx.matchesfashion.com/img/produc...   \n",
       "2  http://assetsprx.matchesfashion.com/img/produc...   \n",
       "3  http://assetsprx.matchesfashion.com/img/produc...   \n",
       "4  http://assetsprx.matchesfashion.com/img/produc...   \n",
       "\n",
       "                                       image_url_alt  price       date  \\\n",
       "0  http://assetsprx.matchesfashion.com/img/produc...  395.0 2016-11-22   \n",
       "1  http://assetsprx.matchesfashion.com/img/produc...  405.0 2016-11-22   \n",
       "2  http://assetsprx.matchesfashion.com/img/produc...  380.0 2016-11-22   \n",
       "3  http://assetsprx.matchesfashion.com/img/produc...  530.0 2016-11-22   \n",
       "4  http://assetsprx.matchesfashion.com/img/produc...  350.0 2016-11-22   \n",
       "\n",
       "     type_1    type_2  \n",
       "0  trainers  hightops  \n",
       "1     derby      lace  \n",
       "2   loafers      None  \n",
       "3     boots     ankle  \n",
       "4     boots      None  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Applying the functions above to the data set\n",
    "Data['type_1']=Data.description.map(lambda x:shoe_type1(x,Shoe_Types))\n",
    "Data['type_2']=Data.apply(lambda x:shoe_type2(x['description'],x['type_1'],Shoe_Types),axis=1)\n",
    "## One shoe type I missed that needs to be aggregated is drivers and driving this is done below\n",
    "Data.type_1=Data.type_1.map(lambda x: 'drivers' if x=='driving' else x)\n",
    "Data.type_2=Data.type_2.map(lambda x: 'drivers' if x=='driving' else x)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data=Data[['id','type_1','type_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rename={'ankle':'boots',\n",
    "        'chelsea':'boots',\n",
    "        'gommino':'loafers',\n",
    "        'moccasin':'loafers',\n",
    "        'sandals':'loafers',\n",
    "        'hightops':'sneakers',\n",
    "        'slippers':'loafers',\n",
    "        'monk':'formal',\n",
    "        'drivers':'loafers',\n",
    "        'oxfords':'formal',\n",
    "        'brogues':'formal',\n",
    "        'trainers':'sneakers',\n",
    "        'derby':'formal',\n",
    "        'loafers':'loafers',\n",
    "        'boots':'boots',\n",
    "        'sneakers':'sneakers'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data=Data[~Data.type_1.isin(['chukka','slip','lace'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replacing shoe type with dictionary\n",
    "Data['Model_1']=Data.type_1.replace(Rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sneakers    5692\n",
       "boots       1555\n",
       "formal      1354\n",
       "loafers     1276\n",
       "Name: Model_1, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1 target variables\n",
    "Data.Model_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Colours=pd.read_csv('Colour_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataframe of all available images\n",
    "Output=pd.merge(left=Data,right=Colours,left_on='id',right_on='ID',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows where shoe type is null\n",
    "Output=Output[~Output.Model_1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Output.to_csv(\"Shoe_IDs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image file location\n",
    "Root_Location='/Users/annacrawford/Desktop/Images_CNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of all file names\n",
    "files=list(Output.id)\n",
    "files=[''.join(['_',str(x),'_a.jpg']) for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve image id from filename in the order to be loaded\n",
    "Image_Order=[x[1:-6] for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all ids have an assosiated file\n",
    "\n",
    "[i for i,x in enumerate(Image_Order) if x==7192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Version 1 creating arrays from images and appending to list\n",
    "Image_Data=[]\n",
    "for x in files:\n",
    "    try:\n",
    "        dloc=''.join([Root_Location,x])\n",
    "        im = Image.open(dloc)\n",
    "        ar = misc.fromimage(im)\n",
    "        Image_Data.append(ar)\n",
    "        \n",
    "    except:\n",
    "        print 'Error processing image :',x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image size\n",
    "\n",
    "Image_Data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9243"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of images\n",
    "\n",
    "len(Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all images are the correct shape\n",
    "\n",
    "[i for i,x in enumerate(Image_Data) if x.shape != (200, 200, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating array from list\n",
    "\n",
    "X=np.array(Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9243, 200, 200, 3)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9243,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define shoe type list\n",
    "\n",
    "y=Output.Model_1\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boots', 'formal', 'loafers', 'sneakers'], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification list\n",
    "\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving X, y file to be used on AWS\n",
    "\n",
    "with file('X_Data.npy', 'w') as Xoutfile:\n",
    "    np.save(Xoutfile,X)\n",
    "with file('y_Data.npy', 'w') as youtfile:    \n",
    "    np.save(youtfile,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sneakers Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Sneaker set\n",
    "\n",
    "Sneakers=Output[Output.Model_1=='sneakers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change sneaker type to sneaker of hightops, depending on description order\n",
    "\n",
    "def sneakers_sub(type_1,type_2):\n",
    "    if type_1=='hightops' or type_2=='hightops':\n",
    "        return 'hightops'\n",
    "    else:\n",
    "        return 'sneakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annacrawford/anaconda/envs/Zaincorp/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "Sneakers['Model_2']=Sneakers.apply(lambda x:sneakers_sub(x['type_1'],x['type_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create file list from image ID\n",
    "\n",
    "sneaker_files=list(Sneakers.id)\n",
    "sneaker_files=[''.join(['_',str(x),'_a.jpg']) for x in sneaker_files]\n",
    "sneaker_Image_Order=[x[1:-6] for x in sneaker_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open each image file appending array to list\n",
    "\n",
    "sneaker_Image_Data=[]\n",
    "for x in sneaker_files:\n",
    "    try:\n",
    "        dloc=''.join([Root_Location,x])\n",
    "        im = Image.open(dloc)\n",
    "        ar = misc.fromimage(im)\n",
    "        sneaker_Image_Data.append(ar)\n",
    "    except:\n",
    "        print 'Error processing image :',x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check arrays are of the correct size\n",
    "[i for i,x in enumerate(sneaker_Image_Data) if x.shape != (200, 200, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5361,)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of shoes\n",
    "y_sneaker=Sneakers.Model_2\n",
    "y_sneaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hightops', 'sneakers'], dtype=object)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification list\n",
    "np.unique(y_sneaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create array from list\n",
    "X_sneaker=np.array(sneaker_Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5361, 200, 200, 3)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sneaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save X, y to file for use in AWS\n",
    "with file('Sneaker_X_Data.npy', 'w') as Xoutfile:\n",
    "    np.save(Xoutfile,X_sneaker)\n",
    "with file('Sneaker_y_Data.npy', 'w') as youtfile:    \n",
    "    np.save(youtfile,y_sneaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Formal shoe set\n",
    "Formal=Output[Output.Model_1=='formal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annacrawford/anaconda/envs/Zaincorp/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "Formal['Model_2']=Formal.type_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create file names from image ID\n",
    "\n",
    "formal_files=list(Formal.id)\n",
    "formal_files=[''.join(['_',str(x),'_a.jpg']) for x in formal_files]\n",
    "formal_Image_Order=[x[1:-6] for x in formal_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open each file, appending array to list\n",
    "formal_Image_Data=[]\n",
    "for x in formal_files:\n",
    "    try:\n",
    "        dloc=''.join([Root_Location,x])\n",
    "        im = Image.open(dloc)\n",
    "        ar = misc.fromimage(im)\n",
    "        formal_Image_Data.append(ar)\n",
    "    except:\n",
    "        print 'Error processing image :',x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check each image has the correct shape\n",
    "\n",
    "[i for i,x in enumerate(formal_Image_Data) if x.shape != (200, 200, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249,)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of images\n",
    "\n",
    "y_formal=Formal.Model_2\n",
    "y_formal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'brogues', u'derby', u'monk', u'oxfords'], dtype=object)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification list\n",
    "\n",
    "np.unique(y_formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_formal=np.array(formal_Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 200, 200, 3)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_formal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to file for use in AWS\n",
    "\n",
    "with file('Formal_X_Data.npy', 'w') as Xoutfile:\n",
    "    np.save(Xoutfile,X_formal)\n",
    "with file('Formal_y_Data.npy', 'w') as youtfile:    \n",
    "    np.save(youtfile,y_formal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Boots set\n",
    "\n",
    "Boots=Output[Output.Model_1=='boots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ankle       292\n",
       "chelsea     247\n",
       "lace        131\n",
       "chukka       80\n",
       "brogues      48\n",
       "monk          9\n",
       "derby         5\n",
       "hightops      5\n",
       "slip          4\n",
       "gommino       2\n",
       "sneakers      2\n",
       "oxfords       1\n",
       "Name: type_2, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boots.type_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define boots subcategory\n",
    "\n",
    "Null_List=['oxfords','sneakers','gommino','slip','hightops','derby','monk','lace']\n",
    "def boots_sub(type_1,type_2):\n",
    "    if type_1!='boots':\n",
    "        return type_1\n",
    "    else:\n",
    "        if type_2 in Null_List or type_2 ==None:\n",
    "            return 'boots'\n",
    "        else:\n",
    "            return type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annacrawford/anaconda/envs/Zaincorp/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# apply subcategory function to dataset\n",
    "\n",
    "Boots['Model_2']=Boots.apply(lambda x:boots_sub(x['type_1'],x['type_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boots      784\n",
       "ankle      293\n",
       "chelsea    249\n",
       "chukka      80\n",
       "brogues     48\n",
       "Name: Model_2, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boots.Model_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create file names from image ID\n",
    "\n",
    "boots_files=list(Boots.id)\n",
    "boots_files=[''.join(['_',str(x),'_a.jpg']) for x in boots_files]\n",
    "boots_Image_Order=[x[1:-6] for x in boots_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open each file, appending its matrix to list\n",
    "\n",
    "boots_Image_Data=[]\n",
    "for x in boots_files:\n",
    "    try:\n",
    "        dloc=''.join([Root_Location,x])\n",
    "        im = Image.open(dloc)\n",
    "        ar = misc.fromimage(im)\n",
    "        boots_Image_Data.append(ar)\n",
    "    except:\n",
    "        print 'Error processing image :',x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if image has the correct shape\n",
    "[i for i,x in enumerate(boots_Image_Data) if x.shape != (200, 200, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1454,)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of boots\n",
    "\n",
    "y_boots=Boots.Model_2\n",
    "y_boots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'ankle', 'boots', u'brogues', u'chelsea', u'chukka'], dtype=object)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification list\n",
    "np.unique(y_boots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_boots=np.array(boots_Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to file for use in AWS\n",
    "\n",
    "with file('Boots_X_Data.npy', 'w') as Xoutfile:\n",
    "    np.save(Xoutfile,X_boots)\n",
    "with file('Boots_y_Data.npy', 'w') as youtfile:    \n",
    "    np.save(youtfile,y_boots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loafers/Slippers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loafer set\n",
    "\n",
    "Loafers=Output[Output.Model_1=='loafers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slip        185\n",
       "gommino      77\n",
       "drivers      18\n",
       "moccasin     10\n",
       "lace          8\n",
       "monk          4\n",
       "brogues       4\n",
       "sneakers      3\n",
       "slippers      1\n",
       "Name: type_2, dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loafers.type_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loafer subcategory\n",
    "\n",
    "Loaf_List=['drivers','slippers']\n",
    "\n",
    "def loafers_sub(type_1,type_2):\n",
    "    if type_1=='moccasin' or type_1=='gommino' :\n",
    "        return 'drivers'\n",
    "    \n",
    "    if type_1!='loafers':\n",
    "        return type_1\n",
    "    else:\n",
    "        if type_2=='moccasin'or type_1=='gommino':\n",
    "            return 'drivers'\n",
    "    \n",
    "        if type_2 in Loaf_List:\n",
    "            return type_2\n",
    "        else:\n",
    "            return 'loafers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annacrawford/anaconda/envs/Zaincorp/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Apply function to dataset\n",
    "\n",
    "Loafers['Model_2']=Loafers.apply(lambda x:loafers_sub(x['type_1'],x['type_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loafers     653\n",
       "drivers     264\n",
       "slippers    172\n",
       "sandals      90\n",
       "Name: Model_2, dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loafers.Model_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create file names from image ID\n",
    "\n",
    "loafers_files=list(Loafers.id)\n",
    "loafers_files=[''.join(['_',str(x),'_a.jpg']) for x in loafers_files]\n",
    "loafers_Image_Order=[x[1:-6] for x in loafers_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open image appending array to list\n",
    "\n",
    "loafers_Image_Data=[]\n",
    "for x in loafers_files:\n",
    "    try:\n",
    "        dloc=''.join([Root_Location,x])\n",
    "        im = Image.open(dloc)\n",
    "        ar = misc.fromimage(im)\n",
    "        loafers_Image_Data.append(ar)\n",
    "    except:\n",
    "        print 'Error processing image :',x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check size of images is correct\n",
    "\n",
    "[i for i,x in enumerate(loafers_Image_Data) if x.shape != (200, 200, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179,)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of shoes\n",
    "\n",
    "y_loafers=Loafers.Model_2\n",
    "y_loafers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drivers', 'loafers', u'sandals', u'slippers'], dtype=object)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification list\n",
    "\n",
    "np.unique(y_loafers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_loafers=np.array(loafers_Image_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 200, 200, 3)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_loafers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to file for use in AWS\n",
    "\n",
    "with file('Loafers_X_Data.npy', 'w') as Xoutfile:\n",
    "    np.save(Xoutfile,X_loafers)\n",
    "with file('Loafers_y_Data.npy', 'w') as youtfile:    \n",
    "    np.save(youtfile,y_loafers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below was copied into a .py script and run on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert arrays to float\n",
    "\n",
    "X=X.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform target variable to categorical\n",
    "\n",
    "Enc=LabelEncoder()\n",
    "y= Enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boots', 'chelsea', 'formal', 'hightops', 'loafers', 'monk',\n",
       "       'sandals', 'sneakers'], dtype=object)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define class list\n",
    "\n",
    "CLass_list = Enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save class list to file\n",
    "\n",
    "with file('Class_list.npy', 'w') as Classfile:\n",
    "    np.save(Classfile,Class_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential() # Define sequential model\n",
    "\n",
    "# The first convolutional layer takes the input of the colour image, which is 200 x 200 in size, and applies \n",
    "# 32 different filters (each 2 X 2) in order to detect features in the shoes. The filters used are chosen, like\n",
    "# the weights in the network, by backpropagation. Each filter is convolved over the input matrix to produce\n",
    "# another image by means of matrix multiplication. An activation function is then applied element \n",
    "# wise to the resulting image. The Relu activation function is defined as the max(0, x), in essence eliminating\n",
    "# negative values.\n",
    "\n",
    "model.add(Convolution2D(nb_filter = 32, nb_col = 3, nb_row = 3, input_shape = (200, 200, 3), activation = 'relu' ))\n",
    "\n",
    "# MaxPooling is then applied to the convoluted image. The purpose of MaxPooling is to down sample the image, thus\n",
    "# reducing the dimentionality of the feature space and allowing for assumptions to be made about features contained \n",
    "# in the sub-regions binned. A 2 x 2 matrix convolves over the image matrix and takes the maximum value contained\n",
    "# within that region. The advantaged of MaxPooling is that it prevents the network from over-fitting and also\n",
    "# reduces the computational time in training.\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout randomly selects 25% of the input units, setting them to zero. This also prevents over-fitting.\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(nb_filter = 32, nb_col = 3, nb_row = 3, activation = 'relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten, flattens the matrix into an array for input into the network.\n",
    "model.add(Flatten())\n",
    "\n",
    "# The initial weights of the nodes in the network are randomly assigned from the Uniform distribution, which are then\n",
    "# updated in the backpropagation process.\n",
    "model.add(Dense(128, init = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(128, init = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Like in most networks, the final layer contains the activation function softmax. The softmax function squashes a \n",
    "# K-dimentional vector z of arbitrary real values, to a K-dimentional vector of real values between 0 and 1 that \n",
    "# sum to 1. The output of the softmax function will be the probability distribution over the different classes.\n",
    "model.add(Dense(8, init = 'uniform', activation = 'softmax')) # 11 classes\n",
    "\n",
    "# To evaluate the weights in the networks we must specify the loss function, and to optimise the weights we must\n",
    "# specify the optimiser. Because this is a classification problem, the loss function used will be binary_crossentropy.\n",
    "# The optimiser adam was chosen for no other reason than efficientsy. The evlauation metric used to judge\n",
    "# the networks performance will be accuracy\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, keras.utils.np_utils.to_categorical(y_train), nb_epoch = 20, batch_size = 32, verbose = 0)\n",
    "\n",
    "Evaluate model\n",
    "score = model.evaluate(X_test, keras.utils.np_utils.to_categorical(y_test))\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model along with model weights\n",
    "\n",
    "model_json=model.to_json()\n",
    "with open(\"model.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
